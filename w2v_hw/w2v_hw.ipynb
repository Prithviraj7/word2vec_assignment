{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "## 0.1 Readings\n",
    "\n",
    "A good resource for today's task (besides the assigned readings from last week) is the following tutorial: [Word2Vec Tutorial: The SkipGram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/). Part 2 provides a really good overview of negative sampling!\n",
    "\n",
    "## 0.2 Task\n",
    "\n",
    "This week your tasks will be:\n",
    "1. Train a CBOW model with a real world dataset, explore how the parameters affect the model.\n",
    "2. Learn how to evaluate an embedding, through intrinsic and extrinsic evaluation.\n",
    "2. Build a SkipGram model, based on your experience on CBOW.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CBOW\n",
    "\n",
    "\n",
    "Our first task is to build our very own CBOW. In this section, you will *NOT* be required to write code for the network. Instead, you will be exploring the model by forming a hypothesis and testing it through different parameter settings.\n",
    "\n",
    "First, let's remind ourselves of the famous quote:\n",
    "\n",
    "> You shall know a word by the company it keeps (Firth, J. R. 1957:11)\n",
    "\n",
    "What this implies is that it is possible to define a word, or *meaning* of a word in a way that describes a prediction task: **the task of predicting the word given the context**. However, one problem still remains: how to represent the meaning of a word? Luckily, there has already been a line of works that suggest a solution: representing the meaning of a word by a vector -- the vector space model.\n",
    "\n",
    "Now let's imagine that we are given a near-perfect vector space model that maps meaning of a word to vector. One of the easiest ways to solve the task then, is that we can literally just use the sum of the context vectors as the inputs, the target word vector as the output, and fit it through a linear model!\n",
    "\n",
    "And that is exactly what CBOW is doing: <img src=\"figures/cbow.png\" alt=\"cobw\" style=\"width: 400px;\"/>\n",
    "\n",
    "The weights between the input and hidden layer are the vector space model mapping, and the weights between the hidden and output layer are the linear prediction model. \n",
    "\n",
    "The only catch is that we don't have that near-perfect vector space model given to us! Thus, our goal is to jointly learn (1) a representation of the word, and (2) a prediction model. In the following sections, we will explore how to do that through PyTorch.\n",
    "\n",
    "\n",
    "\n",
    "## 1.1 Building our training set\n",
    "\n",
    "We want to start with building a training set. For the purpose of this exploratory exercise, you will be using a medium size corpus: the [IMDB movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) (you should already downloaded it in `README.md`)\n",
    "\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "First, we removed all punctuations and lowercased everything, and tokenize it by whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility collections for data processing, make sure you already download the data(see README.md)\n",
    "from utils import read_imdb_data\n",
    "\n",
    "# read_imdb_data removes punctuations and lowercase everything\n",
    "X_raw_train, y_train = read_imdb_data('../data/aclImdb/train')\n",
    "raw_text = ' '.join(X_raw_train).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that it is properly loaded, let's peek into the content a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story of a man who has unnatural feelings for a pig starts out with a opening scene that is a terrific example of absurd comedy a formal orchestra audience is\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(raw_text[:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the Vocab\n",
    "\n",
    "For the purpose of this assignment, and for the sake of training time, we limit the vocabulary to the most common 1000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# pick the top words only\n",
    "raw_text_count = Counter(raw_text)\n",
    "vocab = set(list(zip(*raw_text_count.most_common(1000)))[0])\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then only keep the selected words in the raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter raw text by vocab\n",
    "text = [r for r in raw_text if r in vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 1\n",
    "\n",
    "The preprocessing steps introduced here seem very naive, and potentially problematic. Before you read further down the exercise, based on your understanding of CBOW, \n",
    "\n",
    "1. list three potential concerns with the preprocessing choices, explain why they might be a concern.\n",
    "2. potential fixes for these concerns.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Dataset\n",
    "\n",
    "Now let's build our dataset! First we define some handy helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    '''\n",
    "    helper function to translate context into indexes for inputs\n",
    "    In:\n",
    "        context: a list of words\n",
    "        word_to_ix: a mapping from word to index\n",
    "    Out:\n",
    "        idxs: a list of indexes\n",
    "    '''\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_batcher(X, Y, batches=5):\n",
    "    '''\n",
    "    helper function to batch data, note that batches is not the size of the batch, \n",
    "    but how many batches the dataset is divided into.\n",
    "    In:\n",
    "        X: a matrix of size (num_sample, CONTEXT_SIZE*2)\n",
    "        Y: an array of size (num_sample)\n",
    "        batches: how many batches the dataset is divided into, default:5\n",
    "    Out:\n",
    "        a batch of X and Y\n",
    "    '''\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for i in range(batches):\n",
    "        start = int((i * X.shape[0]) / batches)\n",
    "        end = int(((i + 1) * X.shape[0]) / batches)\n",
    "        yield X[start:end, :], Y[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our given (X) is the context, our target (Y) is the word. \n",
    "\n",
    "We then build our dataset by iterating through the filtered text and mapping the words to indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's set the context window size to 2 for now\n",
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "\n",
    "# A mapping from word to index\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "# iterate through the text to build dataset\n",
    "for i in range(CONTEXT_SIZE, len(text) - CONTEXT_SIZE):\n",
    "    context = [text[i + j] for j in range(-CONTEXT_SIZE, CONTEXT_SIZE+1) if not j==0]\n",
    "    target = text[i]\n",
    "    # the data translate to indexes, X is the context, Y is the target word.\n",
    "    X.append(make_context_vector(context, word_to_ix))\n",
    "    Y.append(word_to_ix[target])\n",
    "\n",
    "# convert to numpy for easier data handling later\n",
    "X = np.array(X, dtype=int)\n",
    "Y = np.array(Y, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 CBOW with PyTorch\n",
    "\n",
    "Now that we have our dataset built, let's import PyTorch!\n",
    "\n",
    "Note: if importing PyTorch failed, first try to click on Kernel->Change Kernel->Python \\[conda env:pytorch_w2v\\] on the upper bar of the notebook. It is likely that you did not set the kernel (which is what the jupyter notebook is running on) to the one you had pytorch installed. If you change the kernel, please re-run this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch\n",
    "import torch\n",
    "# torch.nn contains modules or subcomponents of the network required to train the network.\n",
    "import torch.nn as nn\n",
    "# torch.nn.functional is a collection of handy functions that you can build into the model\n",
    "import torch.nn.functional as F\n",
    "# torch.optim contains optimizers to update the parameters of network\n",
    "import torch.optim as optim\n",
    "\n",
    "\"\"\"\n",
    "Variable in torch.autograd is used to tell pytorch that \n",
    "the object should be put into the PyTorch computation graph. \n",
    "See readings for more details.\n",
    "\"\"\"\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at two modules of pytorch that will be especially useful for our implementation of CBOW: `nn.Embedding` and `nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
      "\n",
      "    This module is often used to store word embeddings and retrieve them using indices.\n",
      "    The input to the module is a list of indices, and the output is the corresponding\n",
      "    word embeddings.\n",
      "\n",
      "    Args:\n",
      "        num_embeddings (int): size of the dictionary of embeddings\n",
      "        embedding_dim (int): the size of each embedding vector\n",
      "        padding_idx (int, optional): If given, pads the output with zeros whenever it encounters the index.\n",
      "        max_norm (float, optional): If given, will renormalize the embeddings to always have a norm lesser than this\n",
      "        norm_type (float, optional): The p of the p-norm to compute for the max_norm option\n",
      "        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the frequency of\n",
      "                                                the words in the mini-batch.\n",
      "        sparse (boolean, optional): if ``True``, gradient w.r.t. weight matrix will be a sparse tensor. See Notes for\n",
      "                                    more details regarding sparse gradients.\n",
      "\n",
      "    Attributes:\n",
      "        weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
      "\n",
      "    Shape:\n",
      "        - Input: LongTensor `(N, W)`, N = mini-batch, W = number of indices to extract per mini-batch\n",
      "        - Output: `(N, W, embedding_dim)`\n",
      "\n",
      "    Notes:\n",
      "        Keep in mind that only a limited number of optimizers support\n",
      "        sparse gradients: currently it's `optim.SGD` (`cuda` and `cpu`),\n",
      "        and `optim.Adagrad` (`cpu`)\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> # an Embedding module containing 10 tensors of size 3\n",
      "        >>> embedding = nn.Embedding(10, 3)\n",
      "        >>> # a batch of 2 samples of 4 indices each\n",
      "        >>> input = Variable(torch.LongTensor([[1,2,4,5],[4,3,2,9]]))\n",
      "        >>> embedding(input)\n",
      "\n",
      "        Variable containing:\n",
      "        (0 ,.,.) =\n",
      "         -1.0822  1.2522  0.2434\n",
      "          0.8393 -0.6062 -0.3348\n",
      "          0.6597  0.0350  0.0837\n",
      "          0.5521  0.9447  0.0498\n",
      "\n",
      "        (1 ,.,.) =\n",
      "          0.6597  0.0350  0.0837\n",
      "         -0.1527  0.0877  0.4260\n",
      "          0.8393 -0.6062 -0.3348\n",
      "         -0.8738 -0.9054  0.4281\n",
      "        [torch.FloatTensor of size 2x4x3]\n",
      "\n",
      "        >>> # example with padding_idx\n",
      "        >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
      "        >>> input = Variable(torch.LongTensor([[0,2,0,5]]))\n",
      "        >>> embedding(input)\n",
      "\n",
      "        Variable containing:\n",
      "        (0 ,.,.) =\n",
      "          0.0000  0.0000  0.0000\n",
      "          0.3452  0.4937 -0.9361\n",
      "          0.0000  0.0000  0.0000\n",
      "          0.0706 -2.1962 -0.6276\n",
      "        [torch.FloatTensor of size 1x4x3]\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Embedding.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n",
      "\n",
      "    Args:\n",
      "        in_features: size of each input sample\n",
      "        out_features: size of each output sample\n",
      "        bias: If set to False, the layer will not learn an additive bias.\n",
      "            Default: ``True``\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
      "          additional dimensions\n",
      "        - Output: :math:`(N, *, out\\_features)` where all but the last dimension\n",
      "          are the same shape as the input.\n",
      "\n",
      "    Attributes:\n",
      "        weight: the learnable weights of the module of shape\n",
      "            (out_features x in_features)\n",
      "        bias:   the learnable bias of the module of shape (out_features)\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> m = nn.Linear(20, 30)\n",
      "        >>> input = autograd.Variable(torch.randn(128, 20))\n",
      "        >>> output = m(input)\n",
      "        >>> print(output.size())\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Linear.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CBOW model\n",
    "\n",
    "Now, it's the exciting part. Let's build our model!\n",
    "\n",
    "Recall that network structure of CBOW is equivalent to $A\\left ( \\sum_{w \\in Context} q_w \\right ) + b$, where $q_w$ is the vector representation of word $w$, A and b are parameters for the linear prediction model. If we applied log softmax to convert the output to log probability, our goal then becomes: \n",
    "\n",
    "$$arg\\max_{A, b, Q} \\log P(w_i|Context) = arg\\max_{A, b, Q} logSoftmax\\left (A\\left ( \\sum_{w \\in Context} q_w \\right ) + b\\right )$$\n",
    "\n",
    "where $Q$ is the matrix of embeddings.\n",
    "\n",
    "With this in mind, our model is thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch implementation of CBOW for exploratory purpose.\n",
    "    \n",
    "    Args:\n",
    "        - vocab_size: size of the vocabulary\n",
    "        - embedding_dim: dimension of the representation vector for words\n",
    "        - word_to_ix: a mapping from word to index\n",
    "    \n",
    "    Shape:\n",
    "        - Input: LongTensor (N, W), N = mini-batch size, W = number of indices to extract per mini-batch\n",
    "        - Output: (N, vocab_size),  N = mini-batch size\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Initializing the model, instanciating the required module (Not linking them)\n",
    "    def __init__(self, vocab_size, embedding_dim, word_to_ix):\n",
    "        # A standard python way of saying CBOW is going to inherit nn.Module\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        self.word_to_ix = word_to_ix\n",
    "        \n",
    "        \"\"\"\n",
    "        We create an nn.Embedding instance with vocab size and embedding dimension specified.\n",
    "        sparse=True enable sparse gradient updates, which speed up the computation and save memory.\n",
    "        \"\"\"\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, sparse=True)\n",
    "       \n",
    "        \"\"\"\n",
    "        We create an nn.Linear instance with embedding_dim as the input features size\n",
    "        and vocab_size as the output size. Recall that the goal of nn.Linear is\n",
    "        a prediction model which maps from an embedding to scores over the vocabulary space.\n",
    "        \"\"\"\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "        \"\"\"\n",
    "        We create an nn.LogSoftmax instance that convert scores to log probility over dim=1, \n",
    "        as we are using dim=0 as the mini-batch dimension.\n",
    "        \"\"\"\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # Here is where we acutally link the modules to describe how the data flow through the network.\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        - inputs: LongTensor (N, W), N = mini-batch size, W = number of indices to extract per mini-batch\n",
    "        - outputs: (N, vocab_size),  N = mini-batch size\n",
    "        \"\"\"\n",
    "        out = self.emb(inputs).sum(dim=1)\n",
    "        out = self.linear(out)\n",
    "        return self.logsoftmax(out)\n",
    "\n",
    "    # helper function to retrieve the trained vector space model (or word embedding)\n",
    "    def word_embedding(self):\n",
    "        return model.emb.weight\n",
    "    \n",
    "    # helper function to do a word to vector lookup\n",
    "    def word2vec(self, word):\n",
    "        return model.emb.weight[self.word_to_ix[word], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there really wasn't many lines of code! Most of those are acutally my comments!\n",
    "\n",
    "\n",
    "### Training\n",
    "\n",
    "Next we need to actually train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy library to help you visualize the progress\n",
    "import progressbar\n",
    "\n",
    "\"\"\"\n",
    "A function to call for training given the model.\n",
    "\n",
    "Parameters for train():\n",
    "    - model: a CBOW instance\n",
    "    - num_epochs: number of time the entire dataset is trained through\n",
    "    - batches:  recall that batches is not the size of the batch, \n",
    "                but how many batches the dataset is divided into.\n",
    "\"\"\"\n",
    "def train(model, num_epochs=5, batches=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    The negative log likelihood loss. \n",
    "    It is useful to train a classification problem with C classes.\n",
    "    Expected to contain log-probabilities of each class. See nn.NLLLoss.__doc__ for more details.\n",
    "    \"\"\"\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    \"\"\"\n",
    "    The stochastic gradient descent optimizer used to update weights, once gradient is computed.\n",
    "    We set a learning rate of 0.001, and momentum of 0.9.\n",
    "    \"\"\"\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # keep track of the loss of the model to see if the model converges.\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # progressbar setting\n",
    "        widgets = ['Epoch {} '.format(epoch), progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]\n",
    "        bar = progressbar.ProgressBar(widgets=widgets, max_value=batches)\n",
    "\n",
    "        for context, target in bar(data_batcher(X, Y, batches)):\n",
    "            \"\"\"\n",
    "            Wrap our training pair context and target first through torch.LongTensor, \n",
    "            and then through Variable.\n",
    "            \n",
    "            torch.LongTensor is a holder for integer variable, and is expected by the model as input.\n",
    "            \n",
    "            Variable is used to put x and y into the PyTorch computation graph. See readings for more details.\n",
    "            \"\"\"\n",
    "            x = Variable(torch.LongTensor(context))\n",
    "            y = Variable(torch.LongTensor(target))\n",
    "            \n",
    "            \"\"\"\n",
    "            zero the parameter gradients\n",
    "        \n",
    "            If you don't do so, the gradients will accumulate and lead to significant slow down.\n",
    "            \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \"\"\"\n",
    "            forward\n",
    "            \n",
    "            The final piece how connecting the network to the data! \n",
    "            We feed the data in, and get a loss value back.\n",
    "            \"\"\"\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            \"\"\"\n",
    "            backward\n",
    "            \n",
    "            This may seem like black magic, but what it really does is \n",
    "            essentially doing chain rule (or a fancier term -- backpropagation)\n",
    "            \n",
    "            Intuitively, for every object x that is a Variable, this calculates\n",
    "            \n",
    "            d loss\n",
    "            -------\n",
    "            d x\n",
    "            \n",
    "            And exactly how to break down the above term to get the actual gradient?\n",
    "            This is done automatically by the computation graph PyTorch build while \n",
    "            you write the model! Thus the name 'autograd'.\n",
    "            \"\"\"\n",
    "            loss.backward()\n",
    "            \n",
    "            \"\"\"\n",
    "            optimize\n",
    "            \n",
    "            Now that for every Variable, we have calculate the gradient, we can use an\n",
    "            optimizer to update the weights!\n",
    "            \n",
    "            SGD for example, does something intuitively like this:\n",
    "            w = w + learning_rate*w.grad\n",
    "            \"\"\"\n",
    "            optimizer.step()\n",
    "            \n",
    "            # just to record the loss\n",
    "            losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib to plot the losses\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 100% |##################################################| Time: 0:03:17\n",
      "Epoch 1 100% |##################################################| Time: 0:03:08\n",
      "Epoch 2 100% |##################################################| Time: 0:03:11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x137190208>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4FOXaBvD7SYHQa+glNJFeDE0QpSpFOSoqHv1ELIiHY/coqAcRu55jVxB7w6OiKAhKE6SDAUINJWCAAJLQEiCkv98fOxs2u7O7s7uz2d3J/buuXNmdeXfmmezm2Zm3jSilQERE1hIV6gCIiMh8TO5ERBbE5E5EZEFM7kREFsTkTkRkQUzuREQWxORORGRBTO5ERBbE5E5EZEExodpx3bp1VUJCQqh2T0QUkTZu3HhcKRXvrVzIkntCQgKSkpJCtXsioogkIgeMlGO1DBGRBTG5ExFZkKHkLiIPicgOEdkuIl+LSJzT+ooi8o2IpIrIehFJCEawRERkjNfkLiKNAdwPIFEp1RFANIAxTsXuBHBKKdUawOsAXjY7UCIiMs5otUwMgEoiEgOgMoAjTutHAfhMezwbwCAREXNCJCIiX3lN7kqpwwD+A+AggKMAspRSi5yKNQZwSCtfCCALQB3nbYnIeBFJEpGkzMzMQGMnIiI3jFTL1ILtzLwFgEYAqojIrc7FdF7qcosnpdRMpVSiUioxPt5rN00iIvKTkWqZwQD+VEplKqUKAPwA4FKnMukAmgKAVnVTA8BJMwO1yysswrd/HEJxMW8PSETkjpHkfhBAbxGprNWjDwKQ4lRmLoCx2uPRAH5TQbo5643vr8Nj329FyycWBGPzRESWYKTOfT1sjaSbAGzTXjNTRKaJyDVasY8A1BGRVAAPA5gUpHix5dDpYG2aiMgyDE0/oJR6GsDTTounOKzPBXCDiXEREVEAOEKViMiCmNyJiCyIyZ2IyIIiOrkfOpkT6hCIiMJSRCf3qXN3hDoEIqKwFNHJ/cS5/FCHQEQUliI6uSezzzsRka6ITu4AkHEmN9QhEBGFnYhP7g98nRzqEIiIwk7EJ/e1+0+EOgQiorAT8cmdiIhcMbkTEVkQkzsRkQUxuRMRWRCTOxGRBRm5h2pbEUl2+MkWkQedylwhIlkOZaa42x4REQWf15t1KKV2A+gKACISDeAwgDk6RVcqpUaaGx4REfnD12qZQQD2KaUOBCMYIiIyh6/JfQyAr92s6yMiW0TkFxHpEGBcPjmXV1iWuyMiCnuGk7uIVABwDYDvdFZvAtBcKdUFwNsAfnSzjfEikiQiSZmZmf7Eq6vD0wtN2xYRkRX4cuY+DMAmpdQx5xVKqWyl1Fnt8QIAsSJSV6fcTKVUolIqMT4+3u+giYjIM1+S+81wUyUjIg1ERLTHPbXtlumkLylHs1FUrMpyl0REYctQcheRygCGAPjBYdkEEZmgPR0NYLuIbAHwFoAxSqkyzbTD3lyJ/y7aXZa7JCIKW167QgKAUioHQB2nZTMcHr8D4B1zQ/PdlnTevIOICOAIVSIiS2JyJyKyICZ3IiILYnInIrIgJnciIguyVHJfnXoCJ87mhToMIqKQs1RyB4Bn5u0MdQhERCFnueTOUapERBZM7kRExORORGRJTO5ERBZkueR++PT5UIdARBRylkvuyYc4eRgRkeWSOxERWTS5nzibh0U7/gp1GEREIWPJ5H77J39g/BcbcSa3INShEBGFhNfkLiJtRSTZ4SdbRB50KiMi8paIpIrIVhHpHryQvTtw4hwAoLg4lFEQEYWO1+SulNqtlOqqlOoK4BIAOQDmOBUbBqCN9jMewHSzA7WrU6WC1zL2MapLd7ncy5uIqFzwtVpmEIB9SqkDTstHAfhc2awDUFNEGpoSoZOhHRp4LXMmtxAA8PC3W4IRAhFR2PM1uY8B8LXO8sYADjk8T9eWlSIi40UkSUSSMjMzfdy1zfBO3pM7EVF5Zzi5i0gFANcA+E5vtc4ylxm8lFIzlVKJSqnE+Ph441GW2pHeroiIyJEvZ+7DAGxSSulVZKcDaOrwvAmAI4EEFkw3zliLUe+uDnUYRERB40tyvxn6VTIAMBfAbVqvmd4AspRSRwOOTkenJjUC3saGtJPYwpGsRGRhhpK7iFQGMATADw7LJojIBO3pAgD7AaQC+ADAP0yOs0SNSrE+lc84k4uESfOxZt/xIEVERBR+YowUUkrlAKjjtGyGw2MFYKK5oZlj0wHbGfqnq9Nwaau6IY6GiKhsWHKEqqN3lu0NdQhERGXO8sl9++FsAJwKmIjKF8snd7sdR7L9fu2Un7Zj8Gu/mxgNEVFwGapzL+8+X+s8IJeIKLyVmzN3dwqKijF17g5knsnz6/VZ5wvw7x+3I7egyOTIiIj8V66S+/ytR7F+/4lSy5amZODTNWl4eu52v7b5xpI9+GLdAXzzxyHvhYmIyki5Su4TZ23CTTPXlTzPyS+ErRfnhemBD57IQVGxy8wJbhVrZe3bISJz5eQXovPUhVi2OyPUoUSUcpXcnbWfshDbDmeVPD94Igf9X12G1xbvDmFURORof+Y5ZOcW4tVf+X/pi3Kd3AFgu9aLRkEh40wuAGDd/pOhDIlCaPPBU5jx+75Qh0EUsHLfW2bFHv+mHnbGShlruPa9NQCACZe3CnEkRIEp92fudgt3HMPrS/b4/DoR36YgHv95Ej5Z/afP+yEy07HsXCzeyTuVWRmTu4PVqSc8ri/2oaHVnUU7j+GZeTuRnVuAZ3/eic0HT+mWy8jOZfdKCprRM9bg7s+TQh0GBRGTu46NB05h6twduPa90nO+f7ByPw6dzDGlZ8zg//6Oj1b9ieumr9Fd3/OFpUH958stKMLri/cgv9D9XcRTM84gYdJ87Ms8G9C+Xlu8B3+khXc7hlIqYno8LduVEfDf89BJTsdhdUzubny6Jg2bD5ae8/3H5CO47JVl+GDlfpfyvuaFDAODplbuDd40xe//vh9vLt2Lz9emuS3zU7LtfivztwY2Nf9bS/fihhlrA9pGsE3/fR9aTF4Q6jAMGffpH2H/9zTLziPZyM4tCHUYXm08cAqdpi7E6Zz8UIdSgsndB4dO5gAANvypX5XizYmz/o2CTZg0H4/P3urXa93JLbRV+Tw3PwXjPtlg6rYj0az1B0MdQsRKOZqN9FM5Qdn28LdW4u8frA/Kts303rJUnMktRFKaf7khGIzerKOmiMwWkV0ikiIifZzWXyEiWSKSrP1MCU644cuxXfV0Tj5+2JTuUuaS55b4vf1vkoI3AnbZbnN6DAXbij2ZSJg0H3uPnQl1KEGVW1CE5+fvxLm8wqDvy4yqqGFvrkS/l5eZEE14W7Y7w+tNf8KpYs/omfubAH5VSl0MoAuAFJ0yK5VSXbWfaaZFGGJDX3edDXJJyjEM+u9yKKWQmmGrj35m3s6S9ff/LxkPf7sF+wOsq9Zz/Gwedv8VeHLTvaO5UqY0GgfLCwtsH7tJP2wLyf6LihVy8oOfcL9cdwAfrPwT7y1PDfq+yLhxn/zh9irCx05zZcJrcheR6gD6A/gIAJRS+UqpcnMD0j3H9BP0vsxzeHPpXqxKdf0mP5ZlGwyVX+S+sdKd3IIij4NoBvxnOa58Y4XP23Wm92H859eb0fIJ7/XOWw6dxuHT53EsOzfgOHyxWztj33jA+6Xvrr+yS6rRzPLY7K1oP2UhAFsV29IU87sS/rr9aElbS2FR+H7RhoNj2bl49ueduPrtVVi513b1mZVTgEI//u+syMggppYAMgF8IiJdAGwE8IBS6pxTuT4isgXAEQCPKqV2mBtq6DnnwzeWmH+XpxvfX4ut6Vlu15/JDd6Zo7uGU8cr9+Nn8zDq3Qu9iNJeGmF4+9m5BagYE4WKMdF+x2jUVW+sBOBbfJ6cOJuH7x2q2m77eAN2HMnGzmlXonIF88YCTvhyk2nbsrp/zd5aMgjxX99txcrHB6DLtEUY06MpXrq+c0hiCqceV0aqZWIAdAcwXSnVDcA5AJOcymwC0Fwp1QXA2wB+1NuQiIwXkSQRScrMjIx6XkdnyqAO1FNiN5PoVsw4l3GVk+d/3/vOUxfhkmeX4KwJf8f0UzlImDQfq3WunHy14c+TSD/luWugc3tJ2nHbuU241GJN/mEbuj+72OfXmZmLiouVbqeB/204iPZTfkVeYRG2Hzbv813g1I3XfqXzY/Jh0/YB2BL2qXPeesGEX72MkeSeDiBdKWWvbJoNW7IvoZTKVkqd1R4vABArIi53o1ZKzVRKJSqlEuPj4/0OumGNOL9fW5aWpnifxU4p25zy/iouNr+ePO34OYyevgbZfl4l5BYU4eNVf+rGdTavEHd99kegIZY04H2rNTSfyytEcbFCl2cW4b+LfJtg6qFvkgOOpyz8c9YmzFyhX2X39YaDOOk1AV0QjDri/y7ejUueW+Jyb4RJP2xDTn4Rnvs5BSPfXoXUjMhqEP9i3QF0M/jFqWC7ut2afhpFxQov/bLLp/fFTF6Tu1LqLwCHRKSttmgQgJ2OZUSkgWjj8EWkp7Zdz8M9A1AtLjKmxHl1obEk0+bJX3Dcz26SPV9Yiu7P+X7G5umf+5l5O5B04JRfc9RvP5yF4W+txLSfd2Le1iO6ZYzUmetxd5Z5JrcAHZ5eiFcX7UbW+QK8/Zu5DZFZ533vZ33whPldA3/eehQvLNhV8lwphStfX4F5Wy78nTs+vRAHTpSuMc0vtN2Q5uS5fGw5dBpXvbGi5G95vqAIT/+0vVRVm1GFRcV457cLVZNLdtpOZk6cs32WcwuKkJVz4W+3Nd3WVHf8rLFkl3yodNNeqC6Slu3yfpLm+P808q1VuOad1Vi2KwMzft+HKT/5d6+IQBntLXMfgK9EZCuArgBeEJEJIjJBWz8awHatzv0tAGNUECufqlSMjOTui00+JrzP1qRBKYXjZ/NwOsfcQR72rpHnHaY/yDiTi5/dJGvA1v1z/tajGPn2KuzPtCWXJ37Yhk99nEfnlg/X4UWtV0za8XNYYmD+E/sVhrcvoxcXpCBh0nyf4gHg85XAnM3p6P/qMqwxocrIk4Iihd3HzuDhby9ceZzNK8SczaWrJRZsO4pP16Th+fkpeGFBCnY59LZ64H+b8dnaA9hyyPc+Ej8lH8F/FrnOx2T/8r5++hp0mbbI4zaUUnht8R7dxu+/+fGF48nsjemmTRRoV1hUXOrLVCngL62jQaF25eppFHgwGcqSSqlkAIlOi2c4rH8HwDsmxuVRbHR4jr06nZOP/KJiFBT7/mY+MWc7vt7gOpDGMRk5/gM8PXcH2tSrWvI8O7cA1eNiAdiqeQRAjIe/k6911WM//gMpR7Px6NCLSi0/dS4fPyYfxswV+3E0q3TvmXP5RZg6r9RFnlerU09gdeoJTB7eDlf8ZzkAW6Oopy8WO2+Xv++vcB1ZbESBU6+VFxek4Fy+a9tDTn4hkg+dxpZDtnrl3cfO4NLWLrWTZeL1xXswpH19dGxcA8Xaedb3OmMvApne2j4QztmTc7bjll7NDd2Ufv/xc3hr6V4s3nkMvzxwmU/7t0/RbdSj320B4Hsju6fJAZ9fkIJPVqehS5Mabsss2nkMg1/7HUsevtyn/QYqPLOkF5OHXRzqEHR1nbYYPZ9fWnLmCgBHs87jvE4icHb8bJ7XwUS/OV0eTvv5QuIc8/6FO0xd9NQv6P+K66CSgqJi5BYUYVt6FjY5Ta3gri4XsM11f+S0rcHR+Uxt/BdJeGbeTpfEHqh1TrdD/OeszX5tx8gZqa91ou6+JNpPWYi/f7De1C6Y+YXF6DDl15I+/ka9uXQvRr69yrQ4zJBy1LWu3X6Bn+/mi8KTfZnOHfZcnc0rRMKk+fhQZ8oQM6zdZ/ucniq5etavsEjNOIvkQ6fx7rKyG7sQkfUb3ZrVCnUIhvV58Te0rV8NL1zXyfRtO15e7zx64SxJKeBIVi4Ki4oRHSUQEfxz1ib87GGOGMe6XF/4MwGV85kwYGsYXu0w+m+Mw+0QvXnWw9XBqHdXY/aEPkhMqK27fs2+46Wqn5zlFRbBSG3vr9v/Knl8zsSBTlvST+NcfhFmerjq0Pt72j3y7RYU+nElqSfzTB4mfrUJbRtUw629m5fMPWSUfdzHByv2Iye/EAMvrm9KXICtKqTdlF9dlt//te2k4Ln5vn05OjLS9mykgdpezTRxQGu/Y/FFRCb3SLP72Blc72b2R194q7v7YMV+3N2/Zcnz1k/+ggcHt8GDgy/ymNiN8KdR0ZMPV+7H9d2b4P0V+/HI0Ivw+doDePZn/STt3EDo7Ncdf3lc7+mqwl6Foud8fpFuwnC28cBJTPhyo9dyvvL2lWIkoehVxZTah0PT2JiZa1G/ehyyzhegXcPqePwq2xVyXmERUo6ewW+7MrAh7SQ2pJ3EF+sOeN+5G0t3ZWDprgzTxiC4k51boDvI0AxZOQWYOGtTSf26nWNLo/1qN1SY3CPI814uzd9fsa9UcgeA/204FHBfZn978njy3PyUkrOpXX9lo3ntym7LXv7qcrfrjJw9+nv4a/cbSwzuuryu238C4/q28PjawqJiPDc/Bf8Y0MrlKig14yyGtDfv7FaP49/Gsf59+e7MkuQ+bd5OfLX+IK7p0sjjtnIKLlyxGD0Z8Oez+dA3yUg64L2t4NIXfzOlMVPvS/SHzemlvjgO6PSOmubmZKWsMLlbyPGz+XjO6QP1V3Yu3lwa2EjaL9cFd8bE5WE6cdkdnxqbT9/dMIOFO47hyOnzaFSzku7642fz8Mqvu/BtUjqOZp1HdFTpLPLbrgzce0Xob/dnv8/waS8J23H0dJdnPPeScWb0jmZ7j51x6Q3kjr+D5bJzCzBt3k5knsnDZ3f01C3jblK3MBnTBiBCG1TJvQ9X8RZ+zu7/ejOe+vHCZGP2L8DComK8/Kt+W4MvXSY9zQVkH2SllMJhp8v02z/ZgG+TbNUm/oxjM2Mckqcz5zmb00tNnHfUSzWDr11y//2j+/7f7hLzIROmFvZ0e8GiYoXOUxdh9sZ0/K51m3Tul79k5zHdLqBGebqHgpmY3KlccLz6sH8BbimjqR4A27iEvi/9hh1HLuzTcaDTkpRjWLDNc9tBMHhqTH7omy3Yc+wszmsNxHszzJ3l9It1B5CmU52x+eApdHx6oe5rzgUw/YWdpzucOTc+HzyR4zKY6sVf3FePGqlmmvLTjpLZZIOJ1TJEAdC78875AtfT8PV/2uqIkw+dRqXYaCjA7+kd7JYEYVZKPe5mRjWDPdHa6+hz8gtx7Xv6nQ8OnjiH+772r0usUfZRtnb9Xw3OPPVlcXcpJncKiHNvgUjR+okFqF898DmK9G5S4di3fv3+k7hhxhr8od2h58k5tqqIO7w0tBphpRkkM8/kof8ry9DaYWCeM72BY3qUMj47Y6epCzGkfX28dmNXAMDEWd7/pkb614cDVstQuVRY7FoHHgxr958oSeyOPjY4LUOwBt+Eo4Mnc7B8t/d5XLzJKyw2PL/QmdxC/LDJ3FkkwwWTO1EYW7jD96qXYNxnoKyYNcHpa4s9N3huP5yFgdr0FoBtVs0zJlSVGDnzLytM7kRU7jw2eyv2H79QvTL5h23oNNW37pvhjsmdiModx+k6QmGajxPq+YPJnYiojDl3rwwGJnciIgticicisiBDyV1EaorIbBHZJSIpItLHab2IyFsikioiW0Wku7ttERFR8BkdxPQmgF+VUqNFpAIA5yn8hgFoo/30AjBd+01ERCHg9cxdRKoD6A/gIwBQSuUrpZxbA0YB+FzZrANQU0Qamh4tEREZYqRapiWATACfiMhmEflQRKo4lWkMwPHuxOnasqCZNqpDMDdPRBTRjCT3GADdAUxXSnUDcA7AJKcyerOPuow1E5HxIpIkIkmZmYHN4X1rr+YBvZ6IyMqMJPd0AOlKqfXa89mwJXvnMk0dnjcB4HKLHKXUTKVUolIqMT4+3p94S0RFmTGbNRGRNXlN7kqpvwAcEpG22qJBAJyHV80FcJvWa6Y3gCylVGA37SQiIr8Z7S1zH4CvtJ4y+wGME5EJAKCUmgFgAYDhAFIB5AAYF4RYiYjIIEPJXSmVDCDRafEMh/UKwEQT4yIiogBwhCoRkQUxuRMRWRCTOxGRBTG5ExFZEJM7EZEFMbkTEVkQkzsRkQUxuRMRWRCTOxGRBTG5ExFZEJM7EZEFMbkTEVkQkzsRkQVFdHL/15VtvRciIiqHIjq5ExGRPkPzuYtIGoAzAIoAFCqlEp3WXwHgJwB/aot+UEpNMy9MIiLyhdE7MQHAAKXUcQ/rVyqlRgYakC+Gd2qIVxfuLstdEhFFhIiulmlRtwpuTGwS6jCIiMKO0eSuACwSkY0iMt5NmT4iskVEfhGRDibF51WLulXLaldERBHDaLVMX6XUERGpB2CxiOxSSq1wWL8JQHOl1FkRGQ7gRwBtnDeifTGMB4BmzZoFGDoREblj6MxdKXVE+50BYA6Ank7rs5VSZ7XHCwDEikhdne3MVEolKqUS4+PjAw6eiIj0eU3uIlJFRKrZHwMYCmC7U5kGIiLa457adk+YHy4RERlhpFqmPoA5Wu6OATBLKfWriEwAAKXUDACjAdwrIoUAzgMYo5RSQYqZiIi88JrclVL7AXTRWT7D4fE7AN4xNzQiIvJXRHeFJCIifUzuREQWxORORGRBTO5ERBYU8cl9eKcGoQ6BiCjsRHxyb16nCrZOHRrqMIiIwkrEJ3ciInLF5E5EZEFM7kREFsTkTkRkQUzuREQWxORORGRBlkjucTHRoQ6BiCisWCK5V4ixxGEQEZmGWZGIyIKY3ImILMhQcheRNBHZJiLJIpKks15E5C0RSRWRrSLS3fxQiYjIKCO32bMboJQ67mbdMABttJ9eAKZrv4mIKATMqpYZBeBzZbMOQE0RaWjStomIyEdGk7sCsEhENorIeJ31jQEccnieri0jIqIQMFot01cpdURE6gFYLCK7lFIrHNaLzmuU8wLti2E8ADRr1sznYImIyBhDZ+5KqSPa7wwAcwD0dCqSDqCpw/MmAI7obGemUipRKZUYHx/vX8REROSV1+QuIlVEpJr9MYChALY7FZsL4Dat10xvAFlKqaOmR+vBTYlNMesutuESEQHGqmXqA5gjIvbys5RSv4rIBABQSs0AsADAcACpAHIAjAtOuO69PLpzWe+SiChseU3uSqn9ALroLJ/h8FgBmGhuaERE5C+OUCUisiAmdyIiC2JyJyKyIMsm98/ucO6tSURUflg2uV9+EfvRE1H5ZdnkTkRUnjG5ExFZkCWT+z2XtwQAPDWiXYgjISIKDV/mc48IaS+NKHlctaLlDo+IyBBLnrkTEZV3lk7uHRrVCHUIREQhYenk3qlJDWydOjTUYRARlTlLJ3cAqB4Xi41PDca6yYNKlo3o3BDXdTN2o6ieLWoHKzQioqCxfHIHgDpVK6JBjbiS59EieO2mroZe++09ffDR2ESf9znrbs4tT0ShUy6Su7Onr25f6vk1XRqVPL7a4bHdpa3q+rwPf15DRGSWcpnc61StCAAY3K6ey7p+rev4tU3Ru4ssEVGIGE7uIhItIptF5GeddbeLSKaIJGs/d5kbZnA4nqUveqg/3vl7t1LrK8R4//OsnTzQZdne54fpln1zjLGqICKiQPly5v4AgBQP679RSnXVfj4MMK4yodSFxxfVr4aRnUtXyWx4YhC8aVA9DgMvroePx/YoWRYbbfuzTr+le6myjWtWCiBaIiLjDCV3EWkCYASAiEjavnKsUrmszYXZJGtWrmDgtYKPb++BARe7VvHUruL99UREwWD0zP0NAI8BKPZQ5noR2Sois0WkqV4BERkvIkkikpSZmelrrGWikYez67jYctlEQUQRyGu2EpGRADKUUhs9FJsHIEEp1RnAEgCf6RVSSs1USiUqpRLj48t+vvVPxvUo05t4xMVGl3reKr4q5vzjUvRMKF9953kFQ1T2jJyK9gVwjYikAfgfgIEi8qVjAaXUCaVUnvb0AwCXmBqlSQa0refXTTzs1TbNalcuWbbhiUFYPcm1MdVR5yYXpj8Y1rEBalWpgG7NauGbe3r7HEOkcZzALaFOZQ8lfTeub4LXvz1Reec1uSulJiulmiilEgCMAfCbUupWxzIi0tDh6TXw3PAaNuwNn3Expc+w3765W6meM3Gx0Xj//y7BV3ddSMr1qsd5bSAV9o900dfPrqaOHh5yEepW9e1qgFVqVN74/YkXkWkico329H4R2SEiWwDcD+B2M4ILtqs6NsB9A1vjCad536/u0sil58yVHRogvlpFj9tbcP9lWPboFWaHaSmOX5D+qhYXi4oOX8j39G/p9TX/17t5wPslMkt0VPBP/HxK7kqp5UqpkdrjKUqpudrjyUqpDkqpLkqpAUqpXcEI1mzRUYJHhrZFjUqxpmyvfaPqaFG3iu66O/q1MGUfkWhMj2aGylV0M65g+aNXoFZl9++R0X+UDU9679pqZf0vikenxq4zpVauEK1TmoKpLK7pea1aRnoE0Ij6xk1dcVe/FvjqrsDmq2nfsLpP5T0lVE9WPT6g1PMbe5TuPOWugbWOh4bX4Z0aul1nVL1qcYYGpllVp8bV0aHRhc+A2Q3dL1/fydTtWVlZ1NiW3096BPlbt8Z4amR79G1dF08Mv7hk+XN/6+jTdu69opXLsldHd3Y7Mdqihy73aftPjWiHTo1roEktzw2om/49xKftGjXCwxdA/eq2ieN66czyOecflwYlnnBTp0rpakUz88uITg1xk8ErNAKkDM7dmdyDzOyGvPH9W2GqNvFZk1qBj3i9IbEpBrWrj4cGX1RqefKUIV7bGBz1alEbd13WEvPu66e7fkDbeEwb1cHt66/q0ABjeuonhwY14nRvmdgq3lYFZh9o3L5R9ZJldvZup+21M9YZt16CZ53iCPRsflRX18nmwtHYSxOCtu2K2ufc/h53bVrT0OvWTh6INeWw51O1uODfApTJPciWPHw5vrzTe3WKL5dpYy9NwJ7nhqFetTjvhQ16YHCbkserJw00NDrXrl61ivjfeM8NpZ+M64nb+iS4XX9523jcN7A19r0wvGRZYvNaSHtpBOJio/Gg9uXz914XvgDmTOwohCtGAAAQJklEQVTrtgH7ll7N0LZ+NUQ5fcKrVIxBR4d657pVKwR8FvWGwemjQ8GebBOb13LbNjGkff2A93O11gGho06dvicNa1RClXJ4r+Ob3ZzImInJPcia1KqMfm30p/917Dc/y00vkgrRrm+RiKBCTBRiot0npUAGSrnr4vnu37vrLhfxvdunXhWKiJRKQI5fGJUqRCPtpRF44doL9brV42JdGrDt8/bf078VFj7U32scgTR02w/Z07G7ayQOFcf5lOyeHN7O7VVgf4PjQqJ86P3h3Paj9xm3OseTqWApf3/VMCAi2DJlKF4d3blkmXN1gl1VD5dvbepVxZPD2+muc75ZSEs3vXgczbj1Esz7p361SucmNTCic0Nc372J1+0Y0b5R6X9wvdQQY/Cf3vG179zcHW/c1BXNPAyccsxv9/R3bYcwatZdvfHdhD4eyzjn0tGXlP777XjmSr/3b0RTrf3D3iDdpn5VlzJRUaLbiwYAPr29h+5yAKWq8uyN4fYTg5GdL3x5f3+v5zaNShWi8bNTdV5ZjiQPhdgy+EJjcg+RGpVjS515u+u54OmSX0Rwt04f78va1HVNjAZOrK7q2ACdmuj/k891Svp39mthat/xQHoPOCbQWlUq4G8Ot1C8b2AbxEQJOjR0Pa6uTWsiOkr86gp492Ut0KtFbZ97QQ1ymmDOU5XEYgNXHp60rV8NfVrVQcq0qzCubwIAoHMTW114YvNapcq+PLoz2tTTT/wPujnLfGBwG+x9fhi+v/fSkuqY+tXjsHPalbjT4YroEqd9VdRph3KuzundMrApOi5uUA1VynkXTyb3MOGYjO29N2KixNBl8Vd39cKShy9HYvNauPuyFvhsXPDOeuxJuG2Danh0aFsArv+8vqikzb/T1EsPG3/1bV0XqS8MRw2dbp32L4WEulUw41bfZsx4ckR7Y1UROtUgRjWqWQmb/j0EL1/fqdR0DkYtfKg/4mKjUalCtEvVkfOXafW4WDx6ZVvd7Tzo1NjuKDY6yuX9r1whRreqKiZKcP/A1m6r9xxVjPE/Mb98fSd8Oq4nnvWxN5nVlL+WjAjga6NU39a2Ov3ZXi5/+7eJR6v4KhjaoQGmL9/nd3x2NSrH4pcHLnM7cMuTBlrXxEnDLkb3ZrVKXTEkTxmCouIAsqIXein5qo4NTNn2/QNb463fUvXXDfK9nrV2lQolXQxv7tkUTWpVxqsLd3t93cQB3qubbuzRFNOX7yvpiXRlB/d/gyeHt8PzC1JQt2pFHD+b57acO6/d2AVdm9ZEy3jXqwOz+dol8/t7++D66WtLnndsXB39Wsdjxu/+/49UrhCNnPwi3XXOt/kMFib3MPLlnb1wNOt80LZfo3Islj5yBfIKizB9+T5TGrLa+Tgwyu667o1RvVIsBl1cz+UM2JeeOmVlZOeG+HnrUa/lhnZoUCq5K+3U/aXrOmFMz2b4ZZv3bbx3S3es2JPpUl304nW2Nhpvyb1OlQr415UXeywDAI9d2RYPDm5j6Cz5zn4t0DK+CgZeXA93f57k0nbgzXU+tNXMCnCwni9axlfBJc19qwKyX0VlnMnF/V9vxrr9J13KxMXqJ/cmtSphXN+yGa3Oahkf3XtFq1Ld8czUr01d3JCoOxV+RBrQ1n2VkohgSPv6PvWycKeb1qfaXaOgUT0SXKuX7Jf2RqeocHfV5a4tQ8/wTg3x0vWdDfdAmurnmaCIuCT2D25LxBd32qr1HP+eUVGCQe3qQ0Tw4dgeuKpj4COG3TXyX9ra+M3lv7+3dIO2c8OsN9/d47lB3JljPb6vXZGnXt0eX99ddjPC8szdR49f5f2MyMrG92+JlXszMVDnzlPOPhzbAwVFnu7vYo6hHRpg/RODSkah+uuLO3sh63wBer2w1KTIgPiqFXEkK9e07em5vW8LTJ230/b40gTc1MP/EwR7n/e9zw9DVIBj5Fc+NsDtALGVjw1ATT+nt3AU4zCQoV/rurpfrk1qVUL6Kf0r4jpVXQfqNahufHBgzUr6V5l6f7nby+iM3Y5n7mHI/k/VxeAoP19Fa9s3kqCdXVS/GtY/MRh1df4pXPYTJS43LAmWQBM7YLuUdt5O31a2KYpHdW2s95ISwzo2KGkcXvrI5fhmfG/se2E4qmtn/GYON7f3Umpdr6rLmeDUazr4XVXmKDY6KuCZC5vWruz2fWlauzKqxXlO7u/+vTtu7W27Snbu3QPYRrd6+v6x9+l37tGkN9rZkd7YhJZuuiq/fH1njO3THPcNbF1qeVmMQPUm9BGQi+gowY8T+/rVUOmOY/16THQUVk8aaGhO9G+8jDyNRI21ATtXd/ZetdAyvqqhnirTHXrbtIqvilZaw+G13RrjxV92oX5191+G02/pjvMFRXj42y1e9+Potj7N0afVhfnxrTZn/YjODTGic0P844rWqF89Dq2eWAAAuOGSJoiNiULDGpWQecZ7464AmDKyPab9vBNdm9bE2zd3w2WvLPMplvdu6Y6r3liJ2k7/MzUqx+KZUR3x1foDpZY3rV0ZaSdyANimpziWHdyrNz1M7mHK6NwcRn1wW+nJwbzdaMSuV8vAb64RbupVi8OuZ6/ye/To+/9nvNvk+P4tMfbSBI9XMMO0AUavLd5jqLFN6fSvXPX4AFSp4P3f2T6eokOjwNonypLzfY1fvaGLz9u4o18LtG9UHT0SapdckfgyN9PFDarj5es7lfRMc+Zc/35Tj6Y4dDIHaSdy8MiQth4H1QWL4eQuItEAkgActs/p7rCuIoDPYbu93gkANyml0kyMkwIQHSVoWrvsP1zhzFOyvatfC3y46k+36z11GXQmYrxqatXjvk2g5Vgj4W0mTrvW9arip4l9XUYIlwe9HU5UfprY1+eJ9zx1sRzcrnQV52Vt4jGkfX3s+etsSBI74Fud+wNwf/u8OwGcUkq1BvA6gJcDDaw8aFgj8FkdjVjOu0ORgy5Na5bJ8Pey9ozTbJ/2Kiu93m1dmtbUbUy1u0Lr6WV0xlDHnk1pL41AjUq2u4X50kvKbIbO3EWkCYARAJ4H8LBOkVEApmqPZwN4R0REKb1pisiuUc1KGNq+PmKDNLnU4Hb1sSTlGM/aybLsDdUdG1cvaeewa1Szkl8jewHbWX7aSyNwNq8Qh930tAl3Rqtl3gDwGIBqbtY3BnAIAJRShSKSBaAOgOMBR2hxM2/Tv1GGGT50cxMOMsbdnCqhNqprY3y57qDb+l8yT9WKMWjbwF3aC29ek7uIjASQoZTaKCJXuCums8zlrF1ExgMYDwDNmvGuLRTejDRQhkKPhNp+n5GGs6WPXI7TOfmhDsMyjHx6+wK4RkSGA4gDUF1EvlRK3epQJh1AUwDpIhIDoAYAlzG5SqmZAGYCQGJiIqtsqNyx1+Fe170xXrsxfG/yEQrO1Sqh4u+9Ze/q1wIJJnZfDpTX5K6UmgxgMgBoZ+6POiV2AJgLYCyAtQBGA/iN9e0Uqey9W5wb0/q1rotVqYHVNA5oWw//urItbjVxumQyz/PXdsR13fy7Z8FTI8tmQjCj/L7uFJFpAJKUUnMBfATgCxFJhe2MfYxJ8RGVuYkDWiMqSlxuhfbR7Yk472amP6OiogQTB7T2XpAMqaMNKurbKrD2h0/G9UBOXhFGGBjYFikkVCfYiYmJKikpKST7JqLI81PyYdSpUtHltpWHTuagYY04w3fuinQislEp5bW3RHi2GBEROXE3vw+7+uorH191RETlDJM7EZEFMbkTEVkQkzsRkQUxuRMRWRCTOxGRBTG5ExFZEJM7EZEFhWyEqohkAjjgtaC+urDOdMI8lvBklWOxynEAPBa75kqpeG+FQpbcAyEiSUaG30YCHkt4ssqxWOU4AB6Lr1gtQ0RkQUzuREQWFKnJfWaoAzARjyU8WeVYrHIcAI/FJxFZ505ERJ5F6pk7ERF5EHHJXUSuEpHdIpIqIpNCHY+diKSJyDYRSRaRJG1ZbRFZLCJ7td+1tOUiIm9px7BVRLo7bGesVn6viIx1WH6Jtv1U7bV6NyX3N/aPRSRDRLY7LAt67O72EYRjmSoih7X3Jlm7H7B93WQtrt0icqXDct3PmYi0EJH1WszfiEgFbXlF7Xmqtj4hwONoKiLLRCRFRHaIyAPa8oh7XzwcSyS+L3EiskFEtmjH8oy/+zfrGN1SSkXMD4BoAPsAtARQAcAWAO1DHZcWWxqAuk7LXgEwSXs8CcDL2uPhAH4BIAB6A1ivLa8NYL/2u5b2uJa2bgOAPtprfgEwzMTY+wPoDmB7Wcbubh9BOJapsN3717lse+0zVBFAC+2zFe3pcwbgWwBjtMczANyrPf4HgBna4zEAvgnwOBoC6K49rgZgjxZvxL0vHo4lEt8XAVBVexwLYL329/Zp/2Yeo9tYzUoQZfGjfRAXOjyfDGByqOPSYkmDa3LfDaChwwd8t/b4fQA3O5cDcDOA9x2Wv68tawhgl8PyUuVMij8BpRNi0GN3t48gHMtU6CeRUp8fAAu1z5ju50z7xz4OIMb582h/rfY4RisnJr4/PwEYEsnvi86xRPT7AqAygE0Aevm6fzOP0d1PpFXLNAZwyOF5urYsHCgAi0Rko4iM15bVV0odBQDtdz1tubvj8LQ8XWd5MJVF7O72EQz/1KorPnaoZvD1WOoAOK2UKnRaXmpb2vosrXzAtEv5brCdJUb0++J0LEAEvi8iEi0iyQAyACyG7Uzb1/2beYy6Ii2569Uzh0t3n75Kqe4AhgGYKCL9PZR1dxy+Lg+FSIx9OoBWALoCOArgv9pyM48lKMcpIlUBfA/gQaVUtqeibvYfNu+LzrFE5PuilCpSSnUF0ARATwDt/Nh/0N+vSEvu6QCaOjxvAuBIiGIpRSl1RPudAWAObG/6MRFpCADa7wytuLvj8LS8ic7yYCqL2N3tw1RKqWPaP2QxgA9ge2/gJWa95ccB1BSRGKflpbalra8B4GQgcYtILGzJ8Cul1A/a4oh8X/SOJVLfFzul1GkAy2Grc/d1/2Yeo65IS+5/AGijtRpXgK2BYm6IY4KIVBGRavbHAIYC2A5bbPbeCWNhq2uEtvw2rYdDbwBZ2uXvQgBDRaSWdok6FLZ6taMAzohIb61Hw20O2wqWsojd3T5MZU9Ummthe2/s+x+j9WhoAaANbI2Mup8zZavsXAZgtE7MjscyGsBvWnl/YxYAHwFIUUq95rAq4t4Xd8cSoe9LvIjU1B5XAjAYQIof+zfzGPWZ2VBSFj+w9QrYA1s915OhjkeLqSVsrdpbAOywxwVbPdlSAHu137W15QLgXe0YtgFIdNjWHQBStZ9xDssTYfvw7wPwDsxtrPsatsviAtjOHO4si9jd7SMIx/KFFutW7Z+qoUP5J7W4dsOhB5K7z5n2Xm/QjvE7ABW15XHa81RtfcsAj6MfbJfdWwEkaz/DI/F98XAskfi+dAawWYt5O4Ap/u7frGN098MRqkREFhRp1TJERGQAkzsRkQUxuRMRWRCTOxGRBTG5ExFZEJM7EZEFMbkTEVkQkzsRkQX9P0df/7p2he/OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125132ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We first initalize a CBOW model of vocab_size 1000 (the top 1000 words we limited it to)\n",
    "and train a vector space model with embbeding dimension=10, since we only have a medium dataset.\n",
    "\"\"\"\n",
    "model = CBOW(vocab_size, 10, word_to_ix)\n",
    "\n",
    "# Train with 3 epochs, 100,000 data batches\n",
    "plt.plot(train(model, 3, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "### This part will be converted to an evaluation part\n",
    "\n",
    "Now let's quickly check our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.8933\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "cos(model.word2vec('movie'), model.word2vec('film'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_n_words(model, vocab, word, n=10):\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "    word_vec = model.word2vec(word)\n",
    "    scores=[]\n",
    "    for v in vocab:\n",
    "        if not v == word:\n",
    "            score = cos(model.word2vec(v), word_vec)\n",
    "            scores.append((score, v))\n",
    "    return list(zip(*(sorted(scores, key=lambda score: score[0].data.numpy(), reverse=True)[:n])))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('film', 'fans', 'as', 'wish', 'wait', 'since', 'roles', 'hate', 'much', 'lee')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_n_words(model, vocab, 'movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 2\n",
    "\n",
    "Now that you learned how to evaluate a vector space model, let's explore the model by changing the parameters!\n",
    "\n",
    "Form **two hypothesis** of how the parameters may affect the model. For each of the hypothesis, do some experiments to prove or disprove your point! Describe the two hypothesis, your experiments, rationale, and results (if any), in the writeup. Don't include code for this part unless nessasary.\n",
    "\n",
    "Also, the definition of parameters are very broad: anything outside of the CBOW model can be considered parameters, including the preprocessing part!\n",
    "\n",
    "Note that you may not be able to sucessfully test the assumption, either due to long training time or lack of training data. The key to the grading will be whether the assumptions are grounded in what we learned in class, and whether the experiments, if sucessfuly ran, would logically support/deny your assumptions.\n",
    "\n",
    "We are also not concerned with whether your performance of embedding beats state-of-the-art, as that is not the purpose of this exploratory assignment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Skipgrams\n",
    "\n",
    "The second task is to train a SkipGram model. Take inspiration from the CBoW classifier trained in the slides, but remember the implementational differences in skipgram.\n",
    "\n",
    "For one, you generally think about it as having 2 embedding matrices, a word-embedding and a context-embedding. Secondly, you're predicting the context from the words, not the other way around. That part won't change your model code, but it will change how you preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = '''\n",
    "it was the best of times it was the worst of times \n",
    "it was the age of wisdom it was the age of foolishness\n",
    "it was the epoch of belief it was the epoch of credulity\n",
    "'''.split()\n",
    "\n",
    "# You'll need to write code that takes in the dataset and creates \n",
    "# the training examples from it. Remember, the training examples\n",
    "# are (w, c) pairs for every word c in the context window of word w.\n",
    "\n",
    "# for instance, on the training set above, the pairs for w = best, and a \n",
    "# will be:\n",
    "#\n",
    "# (best, was)\n",
    "# (best, the)\n",
    "# (best, of)\n",
    "# (best, times)\n",
    "def make_examples(X, context_size=2):\n",
    "    # Your code goes here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \"\"\" Your code goes here. \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created the model, you'll need to train it. I've provided you with a batch function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_data(X, y, batch_size=8):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    count = 0\n",
    "    \n",
    "    while count < X.shape[0]:\n",
    "        yield X[count:(count+batch_size), :], y[count:(count+batch_size)]\n",
    "        count += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1000\n",
    "\n",
    "# Your code goes here.\n",
    "# Remember to instantiate a model, loss function, and optimizer\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    # Your code goes here.\n",
    "    # You should use the batch_data function, but remember to wrap your batches\n",
    "    # in a Variable()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit: Negative Sampling\n",
    "\n",
    "Finally, for those of you who want to take on the challenge, I encourage you to attempt to implement negative sampling! Your two options are to write a general purpose negative sampling loss module, or to wrap the whole thing up into the implementation of Skipgram.\n",
    "\n",
    "The first step will be using a larger dataset to train the vectors on. We'll use the IMDB data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import read_imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = read_imdb_data('../data/aclImdb/test')\n",
    "X = ' '.join(X).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can limit the size of the vocabulary to speed up training as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = [w for w in X if w in vectorizer.vocabulary_.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go through the same process you went through above to generate the training pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NegativeSamplingSkipgram(nn.Module):\n",
    "    \"\"\" Your code goes here. \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1000\n",
    "\n",
    "# Your code goes here.\n",
    "# Remember to instantiate a model, loss function, and optimizer\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    # Your code goes here.\n",
    "    # You should use the batch_data function, but remember to wrap your batches\n",
    "    # in a Variable()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-rg]",
   "language": "python",
   "name": "conda-env-pytorch-rg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
